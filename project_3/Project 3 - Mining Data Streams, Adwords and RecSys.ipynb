{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c461633a",
   "metadata": {},
   "source": [
    "### Enter full names of group members:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4648c5",
   "metadata": {},
   "source": [
    "##### Name A: Nick Askari\n",
    "##### Name B: Simen Peder Stang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "30d55dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sympy import prime\n",
    "from pathlib import Path  # for paths of files\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ANSI escape codes for colors\n",
    "class colors:\n",
    "    red = '\\033[91m'\n",
    "    green = '\\033[92m'\n",
    "    blue = '\\033[94m'\n",
    "    end = '\\033[0m'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4a780",
   "metadata": {},
   "source": [
    "### 1. DGIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287695e",
   "metadata": {},
   "source": [
    "#### 1.1. DGIM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2af55744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default DGIM parameters\n",
    "\n",
    "stream_path = 'data/my_stream.txt'\n",
    "\n",
    "# The window size\n",
    "N = 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3f339cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dgim_algorithm(stream_path, N):\n",
    "    # Buckets list initialization\n",
    "    buckets = []\n",
    "    # Current time in the stream\n",
    "    timestamp = 0\n",
    "\n",
    "    # Open the file containing the stream\n",
    "    with open(stream_path, 'r') as f:\n",
    "        while True:\n",
    "\n",
    "            bit = f.read(1)\n",
    "            if not bit:\n",
    "                break\n",
    "\n",
    "            timestamp = (timestamp + 1) % N\n",
    "\n",
    "            # Remove buckets outside the N-bit window\n",
    "\n",
    "            buckets = [bucket for bucket in buckets if bucket[1] != timestamp]\n",
    "\n",
    "            if bit == '1':\n",
    "                buckets.append((1, timestamp))\n",
    "\n",
    "                # Merging buckets\n",
    "                i = 0\n",
    "                while i < len(buckets) - 2:\n",
    "                    # Find three consecutive buckets of the same size\n",
    "                    if buckets[i][0] == buckets[i + 1][0] and buckets[i][0] == buckets[i + 2][0]:\n",
    "                        # Merge the first two\n",
    "                        new_size = buckets[i][0] * 2\n",
    "                        new_timestamp = buckets[i + 1][1]\n",
    "                        buckets[i + 1] = (new_size, new_timestamp)\n",
    "                        del buckets[i]\n",
    "    \n",
    "                        i = 0\n",
    "                    else:\n",
    "                        i += 1\n",
    "\n",
    "\n",
    "    # Prepare output list\n",
    "    bucket_list = [[] for _ in range(math.ceil(math.log2(N)))]\n",
    "    end_time_stamp = None\n",
    "\n",
    "    # Fill output list and determine end timestamp\n",
    "    for i in range(len(buckets)):\n",
    "        size, ts = buckets[i][0], buckets[i][1]\n",
    "   \n",
    "        index = int(math.log(size) / math.log(2))\n",
    "        if index < len(bucket_list):\n",
    "            bucket_list[index].append(ts)\n",
    "            bucket_list[index].sort()\n",
    "            if size == 1:\n",
    "                end_time_stamp = ts\n",
    "\n",
    "    return bucket_list, end_time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6dc1d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = dgim_algorithm(stream_path, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6966be95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated list of timestamps buckets from DGIM algorithm: \n",
      " [[99], [91, 96], [83, 89], [63, 75], [44], [6], [321, 446], [188], []]\n",
      "The end timestamp: 99\n"
     ]
    }
   ],
   "source": [
    "print(f\"The updated list of timestamps buckets from DGIM algorithm: \\n {bucket[0]}\")\n",
    "print(f\"The end timestamp: {bucket[1]}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c273257",
   "metadata": {},
   "source": [
    "#### 1.2. Query the Bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4cb0343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_count(stream_path, k):\n",
    "    stream_list = []\n",
    "    with open(stream_path, 'r') as file:\n",
    "        for line in file:\n",
    "            stream_list.extend(list(map(int, line.strip())))\n",
    "\n",
    "    # Convert the list into a numpy array\n",
    "    stream_array = np.array(stream_list)\n",
    "    \n",
    "    return int(np.sum(stream_array[-k:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7f7f130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgim_query(bucket, N, k):  \n",
    "    \n",
    "    # Extract the buckets and the end timestamp\n",
    "    bucket_list, end_time_stamp = bucket\n",
    "   \n",
    "    one_count = 0\n",
    "    \n",
    "    last_bucket = 0\n",
    "    for exponent, timestamps in enumerate(bucket_list):\n",
    "        bucket_size = 2 ** exponent\n",
    "        for timestamp in timestamps:\n",
    "            # Calculate the effective range of timestamps to consider\n",
    "            if (end_time_stamp - timestamp) % N < k:\n",
    "                one_count += bucket_size\n",
    "                last_bucket = exponent\n",
    "    \n",
    "    # Adding only half the size of the last bucket (as in the lecture)\n",
    "    if last_bucket:\n",
    "        one_count -= 2**(last_bucket)/2\n",
    "\n",
    "    return math.ceil(one_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "387e5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of queries\n",
    "K = [10, 50, 100, 300, 500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7702bc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "The total 1s in the last 10 bits by DGIM: 4\n",
      "The true count of 1s in the last 10 bits: 5\n",
      "The DGIM error for predicted 1s in the last 10 bits:     20.0 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 50 bits by DGIM: 25\n",
      "The true count of 1s in the last 50 bits: 26\n",
      "The DGIM error for predicted 1s in the last 50 bits:     3.85 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 100 bits by DGIM: 61\n",
      "The true count of 1s in the last 100 bits: 51\n",
      "The DGIM error for predicted 1s in the last 100 bits:     19.61 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 300 bits by DGIM: 173\n",
      "The true count of 1s in the last 300 bits: 150\n",
      "The DGIM error for predicted 1s in the last 300 bits:     15.33 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 500 bits by DGIM: 269\n",
      "The true count of 1s in the last 500 bits: 241\n",
      "The DGIM error for predicted 1s in the last 500 bits:     11.62 %\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------------\")\n",
    "for k in K:\n",
    "    dgim_count = dgim_query(bucket, 500, k)\n",
    "    true_count = actual_count(stream_path, k)\n",
    "    \n",
    "    print(f\"The total 1s in the last {k} bits by DGIM: {dgim_count}\")\n",
    "    print(f\"The true count of 1s in the last {k} bits: {true_count}\")\n",
    "    print(f\"The DGIM error for predicted 1s in the last {k} bits: \\\n",
    "    {round(abs(100*(dgim_count-true_count))/true_count,2)} %\")\n",
    "    print(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaaceac",
   "metadata": {},
   "source": [
    "### 2. Bloom filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "92883c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Username data for the creation of bloom filters - B\n",
    "data_file = (Path(\"data/bloom_username\").with_suffix('.csv'))\n",
    "\n",
    "# Test data to check the functionality and false positive rate\n",
    "test1_file = (Path(\"data/test1_username\").with_suffix('.csv'))\n",
    "test2_file = (Path(\"data/test2_username\").with_suffix('.csv'))\n",
    "\n",
    "# Default bloom filter parameters\n",
    "bloom_size = 1500000 # parameter N\n",
    "h = 3 # number of hash functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "6c5e5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of bloom filter with zeros\n",
    "B = np.zeros(bloom_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1c033746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73d660",
   "metadata": {},
   "source": [
    "#### 2.1. Create Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "75b69edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hash(h, N):\n",
    "    hash_list = []\n",
    "    \n",
    "    # To-do! generate a list of hash functions\n",
    "    prime_dict = {}\n",
    "\n",
    "    for _ in range(h):\n",
    "        random_prime = prime(random.randint(1, 100 * h))\n",
    "        while random_prime in prime_dict:\n",
    "            random_prime = prime(random.randint(1, 100 * h))\n",
    "        prime_dict[random_prime] = True\n",
    "\n",
    "        hash_function = lambda s, p=random_prime, N=N: sum((ord(c) * p**i for i, c in enumerate(s))) % N\n",
    "        hash_list.append(hash_function)\n",
    "    \n",
    "    return hash_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a75aeecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = generate_hash(h, bloom_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0d2d4c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bloom_filter(B, hashes, data):\n",
    "    with data.open() as f:\n",
    "        for name in f:\n",
    "            \n",
    "            # To-do! update the hash index of the bloom filter with 1s\n",
    "            for hash_function in hashes:\n",
    "                B[hash_function(name)] = 1\n",
    "            \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "fe79b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_array = create_bloom_filter(B, hashes, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d7ce957d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff48616",
   "metadata": {},
   "source": [
    "#### 2.2. Verify usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "530485d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_verify_username(bloom_array, hashes, new_user):\n",
    "    \n",
    "    # To-do! verify username and return a code of 0 or 1 (1 - username taken and 0 - username available)\n",
    "    for hash_func in hashes:\n",
    "        index = hash_func(new_user)\n",
    "        if B[index] != 1:\n",
    "            code = 0\n",
    "            break\n",
    "\n",
    "        code = 1\n",
    "        \n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "b6edf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to test different usernames here\n",
    "\n",
    "new_username = \"KazeemTDT4305\"\n",
    "\n",
    "# new_username = \"ShambaTDT4305\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "22690d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_code = single_verify_username(bloom_array, hashes, new_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b7730361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mUsername KazeemTDT4305 is available. Congrats!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if user_code == 1:\n",
    "    print(colors.red + f\"Username {new_username} has been taken. Try again!\" + colors.end)\n",
    "elif user_code == 0:\n",
    "    print(colors.green + f\"Username {new_username} is available. Congrats!\" + colors.end)\n",
    "else:\n",
    "    print(colors.blue + f\"Wrong pass code. Please reverify!\" + colors.end)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "080d7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_verify_username(bloom_array, hashes, data):\n",
    "    # Initialize counts\n",
    "    total_name = 0\n",
    "    taken_name = 0\n",
    "    \n",
    "    with data.open() as f:\n",
    "        for name in f:\n",
    "            # To-do! similar to the single verify, but returns a percentage of usernames taken...\n",
    "            # ...(In other words seen already by the bloom filter during its creation)\n",
    "            \n",
    "            taken_name += single_verify_username(bloom_array, hashes, name)\n",
    "            total_name += 1\n",
    "\n",
    "            \n",
    "    return round(taken_name/total_name*100,2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "4725c4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 1: 100.0%\n",
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 2: 23.93%\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test1_file)\n",
    "print(f\"Percentage of username seen before from test 1: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test2_file)\n",
    "print(f\"Percentage of username seen before from test 2: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00838f24",
   "metadata": {},
   "source": [
    "original. We have correct. The hash functions leads a little bit of randomness\n",
    "----------------------------------------------------------\n",
    "Percentage of username seen before from test 1: 100.0%\n",
    "----------------------------------------------------------\n",
    "Percentage of username seen before from test 2: 23.71%\n",
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488c00b",
   "metadata": {},
   "source": [
    "### 3. Flajolet-Martin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "dae74f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flajolet_martin(input_stream):\n",
    "    R = 0  # Initialize maximum rightmost zero bit position to 0\n",
    "\n",
    "    # To-do! Define hash function h(x) = 6x + 1 mod 5\n",
    "    hash_function = lambda x: 6*x +  1 % 5\n",
    "\n",
    "    # To-do! Iterate over the input stream and update maximum rightmost zero bit position\n",
    "    for i in input_stream:\n",
    "        binary_string = format(i, 'b')\n",
    "\n",
    "        r = 0\n",
    "        for bit in reversed(binary_string):\n",
    "            if bit == '0':\n",
    "                r += 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        if r > R:\n",
    "            R = r\n",
    "\n",
    "    # Estimate the number of distinct elements\n",
    "    distinct_estimate = 2 ** R\n",
    "\n",
    "    return distinct_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c7a283b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 1: 2\n",
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 2: 4\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Input stream\n",
    "input_stream1 = [1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1]\n",
    "input_stream2 = [1, 3, 2, 1, 2, 3, 4, 3, 1, 2, 3, 1]\n",
    "\n",
    "# Run the Flajolet-Martin algorithm\n",
    "distinct_estimate1 = flajolet_martin(input_stream1)\n",
    "distinct_estimate2 = flajolet_martin(input_stream2)\n",
    "\n",
    "# Print the estimated number of distinct elements\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 1:\", distinct_estimate1)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 2:\", distinct_estimate2)\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3051ee5",
   "metadata": {},
   "source": [
    "### 4. Adword "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b08ba",
   "metadata": {},
   "source": [
    "#### 4.1. Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "a58d6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User queries\n",
    "queries = [\"big data\", \"big data\", \"big data\",\"bloom filters\", \"bloom filters\", \"bloom filters\",\n",
    "           \"flajolet martin\", \"flajolet martin\", \"flajolet martin\", \"dgim algorithm\", \"dgim algorithm\", \"dgim algorithm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "66ee11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company A B C and D keywords and budget $$$\n",
    "global_companies = {\n",
    "        'A': [\"big data\", \"bloom filters\", 3],\n",
    "        'B': [\"flajolet martin\", 3],\n",
    "        'C': [\"flajolet martin\", \"dgim algorithm\", 3],\n",
    "        'D': [\"big data\", 3],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "fd6eb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_algorithm(local_companies, queries):\n",
    "    # Initial revenue\n",
    "    revenue = 0\n",
    "    \n",
    "    # To-do! update revenue using greedy algorithm\n",
    "    for query in queries:\n",
    "        potential_advertisers = []\n",
    "\n",
    "        for company, i in local_companies.items():\n",
    "            keywords, budget = i[:-1], i[-1]\n",
    "            \n",
    "            if query in keywords:\n",
    "                if budget > 0:\n",
    "                    potential_advertisers.append(company)\n",
    "            \n",
    "        if len(potential_advertisers) > 0:\n",
    "            chosen_bidder = random.choice(potential_advertisers)\n",
    "            revenue += 1\n",
    "\n",
    "            local_companies[chosen_bidder][-1] -= 1\n",
    "    \n",
    "    return revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "7c9378f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Greedy Algorithm...\n",
      "------------------------------------------------\n",
      "Trial 1 - Revenue generated: 7\n",
      "Trial 2 - Revenue generated: 8\n",
      "Trial 3 - Revenue generated: 9\n",
      "Trial 4 - Revenue generated: 8\n",
      "Trial 5 - Revenue generated: 8\n",
      "Trial 6 - Revenue generated: 9\n",
      "Trial 7 - Revenue generated: 8\n",
      "Trial 8 - Revenue generated: 9\n",
      "Trial 9 - Revenue generated: 9\n",
      "Trial 10 - Revenue generated: 9\n",
      "------------------------------------------------\n",
      "Average revenue generated for all trials:  8.4\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Greedy Algorithm...\")\n",
    "print(\"------------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = greedy_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"------------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fda97",
   "metadata": {},
   "source": [
    "#### 4.2. Balance Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "9af1b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_algorithm(local_companies, queries):\n",
    "    # Initial revenue\n",
    "    revenue = 0\n",
    "    \n",
    "    # We have to choose advertisers with the highest budgets\n",
    "    for query in queries:\n",
    "        potential_advertisers = []\n",
    "\n",
    "        for company, i in local_companies.items():\n",
    "            keywords, budget = i[:-1], i[-1]\n",
    "            \n",
    "            if query in keywords:\n",
    "                if budget > 0:\n",
    "                    potential_advertisers.append((company, budget))\n",
    "        \n",
    "            \n",
    "        if len(potential_advertisers) > 0:\n",
    "            potential_advertisers = sorted(potential_advertisers, key=lambda x: x[1], reverse=True)\n",
    "            highest_budget = potential_advertisers[0][1]\n",
    "\n",
    "            # potential_advertisers are all the companies with the highest budgets now.\n",
    "            potential_advertisers = [comp[0] for comp in potential_advertisers if comp[1] == highest_budget]\n",
    "\n",
    "            chosen_bidder = random.choice(potential_advertisers)\n",
    "            revenue += 1\n",
    "\n",
    "            local_companies[chosen_bidder][-1] -= 1\n",
    "    \n",
    "    return revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "8b975413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Balance Algorithm...\n",
      "-------------------------------------------\n",
      "Trial 1 - Revenue generated: 10\n",
      "Trial 2 - Revenue generated: 9\n",
      "Trial 3 - Revenue generated: 10\n",
      "Trial 4 - Revenue generated: 9\n",
      "Trial 5 - Revenue generated: 9\n",
      "Trial 6 - Revenue generated: 9\n",
      "Trial 7 - Revenue generated: 9\n",
      "Trial 8 - Revenue generated: 9\n",
      "Trial 9 - Revenue generated: 10\n",
      "Trial 10 - Revenue generated: 9\n",
      "-------------------------------------------\n",
      "Average revenue generated for all trials:  9.3\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Balance Algorithm...\")\n",
    "print(\"-------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = balance_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"-------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2ef9e",
   "metadata": {},
   "source": [
    "### 5. Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86174f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings matrix (each row corresponds to a movie, and each column corresponds to a user)\n",
    "ratings_matrix = np.array([\n",
    "    [1, 0, 3, 0, 0, 5, 0, 0, 5, 0, 4, 0],\n",
    "    [0, 0, 5, 4, 0, 0, 4, 0, 0, 2, 1, 3],\n",
    "    [2, 4, 0, 1, 2, 0, 3, 0, 4, 3, 5, 0],\n",
    "    [0, 2, 4, 0, 5, 0, 0, 4, 0, 0, 2, 0],\n",
    "    [0, 0, 4, 3, 4, 2, 0, 0, 0, 0, 2, 5],\n",
    "    [1, 0, 3, 0, 3, 0, 0, 2, 0, 0, 4, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92e8e0",
   "metadata": {},
   "source": [
    "#### 5.1. User-User Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_cf(rate_m, tup_mu, neigh):\n",
    "    \n",
    "    # To-do! implement a user-user CF using cosine similarity as distance measure\n",
    "    \n",
    "    return prediction   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c153de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuple of movie rating by users to be predicted e.g (1, 5) refers to the rating of movie 1 by user 5\n",
    "list_mu_query = [(1, 5), (3, 3)]\n",
    "\n",
    "# Neighbor selection (|N|)\n",
    "neigh = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8e8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 1 by user 5: 1.42 (User-User CF)\n",
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 3 by user 3: 1.49 (User-User CF)\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = user_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (User-User CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217e4ed",
   "metadata": {},
   "source": [
    "#### 5.2. Item-Item Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03be5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_cf(rate_m, tup_mu, neigh):\n",
    "    \n",
    "    # To-do! implement a item-item CF using cosine similarity as distance measure\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 1 by user 5: 2.48 (Item-Item CF)\n",
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 3 by user 3: 3.0 (Item-Item CF)\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = item_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (Item-Item CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892ce96",
   "metadata": {},
   "source": [
    "### Provide concise answers to all 5 cases in the Project 3 description below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc34aad",
   "metadata": {},
   "source": [
    "#### Case 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566a1ec",
   "metadata": {},
   "source": [
    "One has to also consider that each of the buckets used store O(logn) bits for the timestamp. Hence if there are logn buckets, and each of these have a timestamp that is \n",
    "stored with O(logn) bits, this results in a space complexity of O(log^2(N))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b85a6",
   "metadata": {},
   "source": [
    "#### Case 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5e70e3",
   "metadata": {},
   "source": [
    "If the bloom filter outputs that \"Kazeem\" is taken then their is a certain possibility that this is a false positive. This is because with bloom filters, although with create memory usage, it could give out false positives. I would additionally tell the admin that this is highly correlated to the use of hash functions. It is possible that somehow all the hash functions consider a username to be taken, due to imperfected hashes. \n",
    "\n",
    "In this case the bloom filter outputs that a username has NOT been taken. A bloom filter guarantees no have false negatives, hence it is impossible that the username \"KazeemTDT4305\" has been taken. For the bloom filter to return that a username has NOT been taken, only one of the indexes given by one hash function in the bloom filter must be 0. This will not happen if the username was taken. \n",
    "\n",
    "The reason that Google finds that particular email to be taken could be because of false positives when using bloom fitlers as discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16cad2",
   "metadata": {},
   "source": [
    "#### Case 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89efc141",
   "metadata": {},
   "source": [
    "The question is how to increase precision while using the Flaholet-Martin algorithm. This can be done by including several hash functions, and then distributing them into multiple groups. So now you have groups of hash functions. A value from the input stream will now get a value from all these groups. Within each group, the median value out of the hash functions will be chosen. Lastly one takes the average of all the median values obtained from different groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9e628",
   "metadata": {},
   "source": [
    "#### Case 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefef108",
   "metadata": {},
   "source": [
    "### Maximum possible revenue\n",
    "For example as such,\n",
    "\n",
    "- Company D gets all of the queries regarding 'big data'. We have earned 3 dollars then. Company D has no budget left.\n",
    "- Company A gets all of the queries regarding 'bloom filters'. Now we have earned 3 + 3 = 6 dollars. Company A has no budget left.\n",
    "- Company B gets all of the queries regarding 'flajolet martin'. Now we have earned 3 + 3 + 3 = 9 dollars. Company B has no budget left.\n",
    "- Company C gets all of the queries regarding 'dgim algorithm'. Now we have earned 3 + 3 + 3 + 3 = 12 dollars. Company C has no budget left.\n",
    "\n",
    "Such a matching yields a **revenue of 12 dollars.**\n",
    "\n",
    "### Minimum possible revenue\n",
    "- Company A gets all of the queries regarding 'big data'. We have earned 3 dollars then. Company A has no budget left.\n",
    "- Company C gets all of the queries regarding 'flajolet martin'. Now we have earned 3 + 3 = 6 dollars. Company C has no budget left.\n",
    "\n",
    "The user queries left are not wanted by either company B or company D. This outcome yields the minimum revenue, **6 dollars**.\n",
    "\n",
    "### Competitive ratio for the Greedy algorithm\n",
    "We must find the greedy's worst performance. The greedy algorithm picks all the bidders with a relevant keyword (and positive budget). Amongst these, the ultimate bidder is picked randomly. It is possible that it randomly manages to choose the solution with minimum revenue. Hence the greedy algorithms worst performance yields a revenue of 6.\n",
    "\n",
    "Competitive ratio becomes,\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Competitive ratio}_{greedy} = \\frac{6}{12} = \\underline{\\frac{1}{2}}\n",
    "\\end{align}\n",
    "\n",
    "### Competitive ratio for the Balance algorithm\n",
    "The worst possible performance with the balance algorithm, yields the following.\n",
    "\n",
    "- Company A gets 2 x 'big data' and 1 x 'bloom filter'. This yields a revenue of 3. Company A's budget is now 0.\n",
    "- Company B gets 1 x 'flajolet martin'. This yields a revenue of 1. Company B has 2 left in budget.\n",
    "- Company C gets 2 x 'flajolet martin' and 1 x 'dgim algorithm'. This yields a revenue of 3. Company C's budget is now 0.\n",
    "- Company D gets 1 x 'big data'. This yields a revenue of 1. Company D has 2 left in budget.\n",
    "\n",
    "Adding up all the revenues we get,\n",
    "\n",
    "\\begin{align}\n",
    "    R = 3 + 1 + 3 + 1 = \\underline{8}\n",
    "\\end{align}\n",
    "\n",
    "Competitive ratio becomes,\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Competitive ratio}_{balance} = \\frac{8}{12} = \\underline{\\frac{2}{3}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c341065",
   "metadata": {},
   "source": [
    "#### Case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3aa9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
