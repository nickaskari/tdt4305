{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbe62928-01d3-402d-9e45-19d009a4639d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Names of people in the group\n",
    "\n",
    "Please write the names of the people in your group in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15e1606f-bbea-4e98-9f90-bf0a15da5391",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Nick Askari\n",
    "\n",
    "Simen Peder Stang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "389ff132-7e3c-444e-a980-6490e3448153",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loading modules that we need\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Add your imports below this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b384d61-f63a-4c3f-9d87-63e0427c5ecd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# A helper function to load a table (stored in Parquet format) from DBFS as a Spark DataFrame \n",
    "def load_df(table_name: \"name of the table to load\") -> DataFrame:\n",
    "    return spark.read.parquet(table_name)\n",
    "\n",
    "users_df = load_df(\"/user/hive/warehouse/users\")\n",
    "posts_df = load_df(\"/user/hive/warehouse/posts\")\n",
    "\n",
    "# Uncomment if you need\n",
    "# comments_df = load_df(\"/user/hive/warehouse/comments\")\n",
    "# badges_df = load_df(\"/user/hive/warehouse/badges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9b9e457-0510-45fb-8a13-85c006247f0c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### The Problem: Mining the Interests of Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5d203e1-ee4f-4ffe-902b-621c027cff89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n| Id|Reputation|\n+---+----------+\n| -1|         1|\n|  1|       101|\n|  2|       101|\n|  3|       101|\n|  4|       101|\n|  5|       215|\n|  6|       101|\n|  7|       101|\n|  8|       101|\n|  9|      1102|\n+---+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "## To-do!\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "variableA = users_df.select('Id', 'Reputation').orderBy(asc('Id'))\n",
    "\n",
    "variableA.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12fc147d-1cb2-4a67-9ba2-907e761a0739",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+\n|OwnerUserId|          Diversity|\n+-----------+-------------------+\n|       1330|0.48746081504702193|\n|      64377|0.46551724137931033|\n|      45264|0.32445141065830724|\n|      14675|0.31347962382445144|\n|      80885| 0.3056426332288401|\n|      58341|0.30094043887147337|\n|      55122|0.28213166144200624|\n|      65131| 0.2664576802507837|\n|        836| 0.2476489028213166|\n|      86339|0.24294670846394983|\n|      28175|0.23981191222570533|\n|      71442| 0.2335423197492163|\n|      38887| 0.2225705329153605|\n|      50727| 0.2225705329153605|\n|       8878|0.21786833855799373|\n|      67328|0.21630094043887146|\n|       null|0.21473354231974923|\n|        924| 0.2115987460815047|\n|      29587| 0.2115987460815047|\n|        381|0.21003134796238246|\n+-----------+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, col, collect_set, size\n",
    "\n",
    "# It is 147 rows in posts where PostTypeId = 2 and OwnerUserId = Null\n",
    "\n",
    "answers = posts_df.filter(\"PostTypeId = 2\")\n",
    "questions = posts_df.filter(\"PostTypeId = 1\")\n",
    "\n",
    "# Make aliases to avoid error\n",
    "answers_alias = answers.alias(\"ans\")\n",
    "questions_alias = questions.alias(\"ques\")\n",
    "\n",
    "# Joining answers with questions in order to find the tags\n",
    "answers_with_tags = answers_alias.join(questions_alias, col(\"ans.ParentId\") == col(\"ques.Id\"), \"inner\")\\\n",
    "                                 .select(col(\"ans.OwnerUserId\"), col(\"ques.Tags\"))\n",
    "\n",
    "# Fixing the tag column --> one row for each tag\n",
    "tags_exploded = answers_with_tags.withColumn(\"Tags\", explode(split(col(\"tags\"), \"><\")))\n",
    "tags_cleaned = tags_exploded.withColumn(\"Tags\", regexp_replace(col(\"Tags\"), \"^<|>$\", \"\"))\n",
    "\n",
    "# Count distinct tags\n",
    "result = tags_cleaned.groupBy(\"OwnerUserId\").agg(countDistinct(\"Tags\").alias(\"distinct_tags_count\"))\n",
    "\n",
    "# Finally, variableB (removing 'distinct_tags_count' column)\n",
    "variableB = result.withColumn('Diversity', col('distinct_tags_count') / 638).select('OwnerUserId', 'Diversity').orderBy(desc('Diversity'))\n",
    "\n",
    "variableB.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29b84400-d5c3-4750-9dec-05a8a2c96d9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pearson correlation coefficient between Variable A and Variable B is,\n 0.721767764862296\n"
     ]
    }
   ],
   "source": [
    "# We must join variableA and variableB on their respective id's\n",
    "\n",
    "joined_table = variableA.join(variableB, variableA.Id == variableB.OwnerUserId, how='inner')\n",
    "\n",
    "correlation = joined_table.stat.corr('Diversity', 'Reputation')\n",
    "\n",
    "print(\"The Pearson correlation coefficient between Variable A and Variable B is,\\n\", correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7359d783-02c9-45d6-a3d2-76f941c9530e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Answers to questions\n",
    "\n",
    "\n",
    "**Do expert users have specific interests, or do they have general interests?**\n",
    "\n",
    "The correlation between a users reputation and diversity score is strongly positive. This indicates that expert users (users with high reputation) tend to answer questions related to many topics (many distinct tags), and hence have general interests.\n",
    "\n",
    "A positive correlation means that the higher the reputation, the higher the number of distinct tags in questions answered. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d9754d0-803f-48e8-a7be-693f5657a67d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Task4",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
