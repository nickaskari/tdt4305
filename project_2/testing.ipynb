{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3664,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser  # for reading the parameters file\n",
    "import sys  # for system errors and printouts\n",
    "from pathlib import Path  # for paths of files\n",
    "import os  # for reading the input data\n",
    "import time  # for timing\n",
    "import numpy as np  # for creating matrices or arrays\n",
    "import random  # for randomly generating a and b for hash functions\n",
    "from itertools import combinations  # for creating candidate pairs in lsh\n",
    "import re\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3665,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_file = 'default_parameters.ini'  # the main parameters file\n",
    "data_main_directory = Path('data')\n",
    "parameters_dictionary = dict()\n",
    "document_list = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3666,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_prime(N):\n",
    "    def is_prime(n):\n",
    "        if n <= 2:\n",
    "            return n == 2\n",
    "        if n % 2 == 0:\n",
    "            return False\n",
    "        p = 3\n",
    "        while p * p <= n:\n",
    "            if n % p == 0:\n",
    "                return False\n",
    "            p += 2\n",
    "        return True\n",
    "\n",
    "    prime = N + 1\n",
    "    while not is_prime(prime):\n",
    "        prime += 1\n",
    "    return prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3667,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parameters():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(parameter_file)\n",
    "    for section in config.sections():\n",
    "        for key in config[section]:\n",
    "            if key == 'data':\n",
    "                parameters_dictionary[key] = config[section][key]\n",
    "            elif key == 'naive':\n",
    "                parameters_dictionary[key] = bool(config[section][key])\n",
    "            elif key == 't':\n",
    "                parameters_dictionary[key] = float(config[section][key])\n",
    "            else:\n",
    "                parameters_dictionary[key] = int(config[section][key])\n",
    "\n",
    "\n",
    "read_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3668,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    for (root, dirs, file) in os.walk(data_path):\n",
    "        for f in file:\n",
    "            file_path = data_path / f\n",
    "            doc = open(file_path).read().strip().replace('\\n', ' ')\n",
    "            file_id = int(file_path.stem)\n",
    "            document_list[file_id] = doc\n",
    "\n",
    "\n",
    "data_folder = data_main_directory / parameters_dictionary['data']\n",
    "read_data(data_folder)\n",
    "document_list = {k: document_list[k] for k in sorted(document_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the toy data to test, remove stop words as in Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3669,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence_1 = \" Big Data platform  students  Blackboard\"\n",
    "Sentence_2 = \"Questions  MinHash project NTNU students Piazza\"\n",
    "Sentence_3 = \"NTNU Big Data platform  Blackboard  Piazza\"\n",
    "Sentence_4 = \" project data  students   Blackboard  Piazza\"\n",
    "\n",
    "Sentence_1, Sentence_2, Sentence_3, Sentence_4 = [sentence.lower()\n",
    "                                                  for sentence in [Sentence_1, Sentence_2, Sentence_3, Sentence_4]]\n",
    "\n",
    "document_list = {1: Sentence_1, 2: Sentence_2, 3: Sentence_3, 4: Sentence_4}\n",
    "\n",
    "shingles = ['big', 'blackboard', 'data', 'minhash', 'ntnu',\n",
    "                'piazza', 'platform', 'project', 'questions', 'students']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :   big data platform  students  blackboard\n",
      "2 :  questions  minhash project ntnu students piazza\n",
      "3 :  ntnu big data platform  blackboard  piazza\n",
      "4 :   project data  students   blackboard  piazza\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(document_list)):\n",
    "    print(i + 1, ': ', document_list[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKS!\n",
    "def k_shingles():\n",
    "    docs_k_shingles = []\n",
    "    k = parameters_dictionary['k']\n",
    "\n",
    "    for _, document in document_list.items():\n",
    "\n",
    "        cleaned_doc = ''.join(\n",
    "            c for c in document if c.isalnum() or c.isspace())\n",
    "        words = cleaned_doc.split()\n",
    "        k_shingles_set = set(' '.join(words[i:i+k])\n",
    "                             for i in range(len(words) - k + 1))\n",
    "        docs_k_shingles.append(k_shingles_set)\n",
    "\n",
    "    return docs_k_shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  {'big data platform students blackboard'}\n",
      "2 :  {'minhash project ntnu students piazza', 'questions minhash project ntnu students'}\n",
      "3 :  {'ntnu big data platform blackboard', 'big data platform blackboard piazza'}\n",
      "4 :  {'project data students blackboard piazza'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'big data platform students blackboard'},\n",
       " {'minhash project ntnu students piazza',\n",
       "  'questions minhash project ntnu students'},\n",
       " {'big data platform blackboard piazza', 'ntnu big data platform blackboard'},\n",
       " {'project data students blackboard piazza'}]"
      ]
     },
     "execution_count": 3672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs_k_shingles = k_shingles()\n",
    "for i in range(len(all_docs_k_shingles)):\n",
    "    print(i + 1, ': ', all_docs_k_shingles[i])\n",
    "\n",
    "\n",
    "all_docs_k_shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3673,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signature_set(k_shingles):\n",
    "\n",
    "    all_unique_shingles = set().union(*k_shingles)  # can add *k_shingles instead\n",
    "    all_unique_shingles_list = list(all_unique_shingles)\n",
    "\n",
    "    shingle_to_index = {shingle: idx for idx,\n",
    "                        shingle in enumerate(all_unique_shingles_list)}\n",
    "\n",
    "    num_docs = len(k_shingles)\n",
    "    num_shingles = len(all_unique_shingles)\n",
    "    input_matrix = np.zeros((num_shingles, num_docs), dtype=int)\n",
    "\n",
    "    for doc_idx, shingles_set in enumerate(k_shingles):\n",
    "        for shingle in shingles_set:\n",
    "            shingle_idx = shingle_to_index[shingle]\n",
    "            input_matrix[shingle_idx, doc_idx] = 1\n",
    "\n",
    "    return input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0]])"
      ]
     },
     "execution_count": 3674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix = signature_set(all_docs_k_shingles)\n",
    "input_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test (above) = actual (in task 1) \n",
    "\n",
    "1 = 1 \n",
    "\n",
    "2 = 10\n",
    "\n",
    "\n",
    "3 = 4\n",
    "\n",
    "\n",
    "4 = 3\n",
    "\n",
    "\n",
    "5 = 6\n",
    "\n",
    "\n",
    "6 = 8\n",
    "\n",
    "\n",
    "7 = 5\n",
    "\n",
    "\n",
    "8 = 9\n",
    "\n",
    "\n",
    "9 = 7\n",
    "\n",
    "\n",
    "10 = 2\n",
    "\n",
    "I.e all rows (shingles / Unique words) are present, but in a different order (not alphabetially sorted). OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4)"
      ]
     },
     "execution_count": 3675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix.shape[0], input_matrix.shape[1]\n",
    "# Num Shingles X Num Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3676,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hash_functions(num_perm, N):\n",
    "    hash_funcs = []\n",
    "    for i in range(1, num_perm + 1):\n",
    "        a = random.randint(1, N)\n",
    "        b = random.randint(0, N)\n",
    "        p = next_prime(N)\n",
    "        hash_func = (lambda x, a=a, b=b, p=p: ((a * x + b) %\n",
    "                     (p)) + 1, {'a': a, 'b': b, 'p': p})\n",
    "        hash_funcs.append(hash_func)\n",
    "    return hash_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3677,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minHash(docs_signature_sets, hash_fn):\n",
    "\n",
    "    input_matrix = docs_signature_sets  # for simplicity and readability\n",
    "\n",
    "    num_shingles = input_matrix.shape[0]  # num rows\n",
    "    num_docs = input_matrix.shape[1]  # num columns\n",
    "    num_permutation = len(hash_fn)\n",
    "    min_hash_signatures = np.full((num_permutation, num_docs), np.inf)\n",
    "\n",
    "    for shingle in range(num_shingles):  # for each shingle, row\n",
    "        for doc in range(num_docs):  # for each doc, column\n",
    "            # ensures that hash functions are applied only to shingles that actually appear in the document\n",
    "            if input_matrix[shingle, doc] == 1:\n",
    "                for permutation, (hash_func, params) in enumerate(hash_fn):\n",
    "                    shingle_hash = hash_func(shingle, **params)\n",
    "                    min_hash_signatures[permutation, doc] = min(  # permutation is the row, doc is the column if Sig_M\n",
    "                        min_hash_signatures[permutation, doc], shingle_hash)\n",
    "\n",
    "    return min_hash_signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3678,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hash_fn = generate_hash_functions(parameters_dictionary['permutations'], len(input_matrix))\n",
    "hash_fn = generate_hash_functions(100, len(input_matrix))\n",
    "min_hash_signatures = minHash(input_matrix, hash_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 1., 5., 2.],\n",
       "       [6., 4., 1., 2.],\n",
       "       [3., 5., 4., 2.],\n",
       "       [1., 3., 4., 5.],\n",
       "       [6., 1., 2., 3.],\n",
       "       [2., 3., 1., 4.],\n",
       "       [2., 1., 3., 7.],\n",
       "       [3., 1., 2., 4.],\n",
       "       [6., 2., 4., 1.],\n",
       "       [1., 2., 6., 3.],\n",
       "       [7., 2., 3., 4.],\n",
       "       [3., 2., 4., 1.],\n",
       "       [5., 1., 2., 4.],\n",
       "       [7., 4., 1., 5.],\n",
       "       [6., 1., 2., 3.],\n",
       "       [3., 1., 2., 4.],\n",
       "       [2., 4., 3., 1.],\n",
       "       [4., 3., 2., 1.],\n",
       "       [3., 5., 4., 2.],\n",
       "       [7., 1., 2., 3.],\n",
       "       [1., 5., 4., 2.],\n",
       "       [4., 3., 2., 1.],\n",
       "       [4., 2., 1., 7.],\n",
       "       [4., 1., 3., 5.],\n",
       "       [7., 2., 3., 4.],\n",
       "       [5., 4., 1., 2.],\n",
       "       [1., 3., 4., 5.],\n",
       "       [4., 2., 1., 7.],\n",
       "       [1., 3., 4., 5.],\n",
       "       [2., 1., 5., 6.],\n",
       "       [6., 1., 2., 3.],\n",
       "       [5., 2., 6., 3.],\n",
       "       [7., 1., 5., 2.],\n",
       "       [7., 4., 3., 1.],\n",
       "       [3., 1., 5., 6.],\n",
       "       [7., 4., 1., 5.],\n",
       "       [6., 1., 3., 5.],\n",
       "       [3., 2., 4., 1.],\n",
       "       [3., 2., 4., 1.],\n",
       "       [1., 3., 4., 5.],\n",
       "       [4., 6., 1., 3.],\n",
       "       [4., 6., 1., 3.],\n",
       "       [1., 3., 4., 5.],\n",
       "       [6., 3., 2., 7.],\n",
       "       [2., 1., 5., 6.],\n",
       "       [2., 1., 3., 7.],\n",
       "       [4., 1., 3., 5.],\n",
       "       [7., 1., 2., 3.],\n",
       "       [3., 2., 4., 1.],\n",
       "       [7., 4., 1., 5.],\n",
       "       [6., 3., 1., 4.],\n",
       "       [3., 2., 4., 1.],\n",
       "       [4., 3., 2., 1.],\n",
       "       [2., 4., 3., 1.],\n",
       "       [7., 4., 1., 5.],\n",
       "       [4., 1., 3., 5.],\n",
       "       [3., 2., 1., 7.],\n",
       "       [3., 4., 1., 5.],\n",
       "       [4., 1., 3., 5.],\n",
       "       [7., 4., 3., 1.],\n",
       "       [6., 1., 3., 5.],\n",
       "       [3., 1., 5., 6.],\n",
       "       [1., 3., 2., 7.],\n",
       "       [2., 1., 5., 6.],\n",
       "       [6., 1., 3., 5.],\n",
       "       [3., 2., 1., 7.],\n",
       "       [3., 1., 2., 4.],\n",
       "       [7., 4., 3., 1.],\n",
       "       [6., 1., 3., 5.],\n",
       "       [4., 1., 5., 2.],\n",
       "       [7., 4., 1., 5.],\n",
       "       [3., 2., 4., 1.],\n",
       "       [1., 5., 2., 6.],\n",
       "       [3., 2., 4., 1.],\n",
       "       [1., 3., 4., 5.],\n",
       "       [3., 1., 5., 6.],\n",
       "       [2., 3., 4., 5.],\n",
       "       [7., 1., 2., 3.],\n",
       "       [6., 3., 2., 7.],\n",
       "       [3., 5., 4., 2.],\n",
       "       [1., 5., 4., 2.],\n",
       "       [5., 1., 3., 7.],\n",
       "       [6., 2., 4., 1.],\n",
       "       [3., 5., 4., 2.],\n",
       "       [7., 1., 5., 2.],\n",
       "       [1., 2., 3., 4.],\n",
       "       [7., 4., 3., 1.],\n",
       "       [3., 1., 2., 4.],\n",
       "       [5., 2., 6., 3.],\n",
       "       [2., 1., 3., 7.],\n",
       "       [2., 3., 1., 4.],\n",
       "       [4., 2., 1., 7.],\n",
       "       [2., 3., 4., 5.],\n",
       "       [6., 4., 1., 2.],\n",
       "       [7., 2., 3., 4.],\n",
       "       [3., 4., 1., 5.],\n",
       "       [1., 5., 2., 6.],\n",
       "       [4., 5., 2., 6.],\n",
       "       [2., 1., 3., 7.],\n",
       "       [1., 5., 2., 6.]])"
      ]
     },
     "execution_count": 3679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permutations x Num_Documents\n",
    "min_hash_signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3680,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_jaccard_similarity = [0.1, 0.5714, 0.4285, 0.2, 0.375, 0.375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity between Sentence 1 and Sentence 2 is 0.0\n",
      "Jaccard Similarity between Sentence 1 and Sentence 3 is 0.0\n",
      "Jaccard Similarity between Sentence 1 and Sentence 4 is 0.0\n",
      "Jaccard Similarity between Sentence 2 and Sentence 3 is 0.0\n",
      "Jaccard Similarity between Sentence 2 and Sentence 4 is 0.0\n",
      "Jaccard Similarity between Sentence 3 and Sentence 4 is 0.0\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(matrix, i, j):\n",
    "    return np.sum(matrix[:, i] == matrix[:, j]) / matrix.shape[0]\n",
    "\n",
    "'''\n",
    "If we let the number og permutations grow large, the error from true similarity decreases. I.e., it works \n",
    "However, its a bit trash, need like 1000 permuatations for the result to be decent. And 1000 rows is more\n",
    "than the original, and there is no computational gain, but this may be because our data is so small\n",
    "'''\n",
    "\n",
    "for i in range(min_hash_signatures.shape[1]):\n",
    "    for j in range(i + 1, min_hash_signatures.shape[1]):\n",
    "        print(\n",
    "            f\"Jaccard Similarity between Sentence {i + 1} and Sentence {j + 1} is {jaccard_similarity(min_hash_signatures, i, j)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3682,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsh(min_hash_signatures):\n",
    "\n",
    "    b = parameters_dictionary['b']\n",
    "    num_rows = min_hash_signatures.shape[0]  # num permutations\n",
    "    num_docs = min_hash_signatures.shape[1]\n",
    "    rows_per_band = num_rows // b  # divide the rows of the signature matrix into b bands\n",
    "    candidates = set()\n",
    "\n",
    "    for band in range(b):\n",
    "        start_index = band * rows_per_band\n",
    "        end_index = start_index + rows_per_band\n",
    "        buckets = {}\n",
    "\n",
    "        for doc in range(num_docs):\n",
    "            # extract MinHash values for the current document in the current band\n",
    "            band_slice = tuple(min_hash_signatures[start_index:end_index, doc])\n",
    "            print(band_slice)\n",
    "            band_hash = hash(band_slice)\n",
    "            print(band_hash)\n",
    "            if band_hash not in buckets:\n",
    "                buckets[band_hash] = [doc]\n",
    "            else:\n",
    "                for candidate_doc in buckets[band_hash]:\n",
    "                    candidates.add((candidate_doc, doc))\n",
    "                buckets[band_hash].append(doc)\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.0, 6.0, 3.0, 1.0, 6.0)\n",
      "-1404534377251821405\n",
      "(1.0, 4.0, 5.0, 3.0, 1.0)\n",
      "-582485975262488327\n",
      "(5.0, 1.0, 4.0, 4.0, 2.0)\n",
      "-8906811249165081092\n",
      "(2.0, 2.0, 2.0, 5.0, 3.0)\n",
      "-8377305782804328457\n",
      "(2.0, 2.0, 3.0, 6.0, 1.0)\n",
      "2113126137666713194\n",
      "(3.0, 1.0, 1.0, 2.0, 2.0)\n",
      "6241205306661066447\n",
      "(1.0, 3.0, 2.0, 4.0, 6.0)\n",
      "-6305498743342790870\n",
      "(4.0, 7.0, 4.0, 1.0, 3.0)\n",
      "-8493525859713514233\n",
      "(7.0, 3.0, 5.0, 7.0, 6.0)\n",
      "1960841052811665867\n",
      "(2.0, 2.0, 1.0, 4.0, 1.0)\n",
      "-4144346545389656819\n",
      "(3.0, 4.0, 2.0, 1.0, 2.0)\n",
      "3112524076205350403\n",
      "(4.0, 1.0, 4.0, 5.0, 3.0)\n",
      "-8537250652368104507\n",
      "(3.0, 2.0, 4.0, 3.0, 7.0)\n",
      "6780078700826965266\n",
      "(1.0, 4.0, 3.0, 5.0, 1.0)\n",
      "-4729945923772302536\n",
      "(2.0, 3.0, 2.0, 4.0, 2.0)\n",
      "6220349440742185675\n",
      "(4.0, 1.0, 1.0, 2.0, 3.0)\n",
      "-8438153806684176286\n",
      "(1.0, 4.0, 4.0, 4.0, 7.0)\n",
      "3059798096485113988\n",
      "(5.0, 3.0, 2.0, 1.0, 2.0)\n",
      "-9148755222282865386\n",
      "(4.0, 2.0, 1.0, 3.0, 3.0)\n",
      "-2325550999726738870\n",
      "(2.0, 1.0, 7.0, 5.0, 4.0)\n",
      "871000895491068085\n",
      "(5.0, 1.0, 4.0, 1.0, 2.0)\n",
      "-1166675331747248844\n",
      "(4.0, 3.0, 2.0, 3.0, 1.0)\n",
      "-5813637694634019562\n",
      "(1.0, 4.0, 1.0, 4.0, 5.0)\n",
      "-3499642436355884812\n",
      "(2.0, 5.0, 7.0, 5.0, 6.0)\n",
      "4573740153215587437\n",
      "(6.0, 5.0, 7.0, 7.0, 3.0)\n",
      "-5642125776885489215\n",
      "(1.0, 2.0, 1.0, 4.0, 1.0)\n",
      "-1510531987844092700\n",
      "(2.0, 6.0, 5.0, 3.0, 5.0)\n",
      "-6516396071097395428\n",
      "(3.0, 3.0, 2.0, 1.0, 6.0)\n",
      "-3068415610348462705\n",
      "(7.0, 6.0, 3.0, 3.0, 1.0)\n",
      "299559238654997551\n",
      "(4.0, 1.0, 2.0, 2.0, 3.0)\n",
      "867546951413824624\n",
      "(1.0, 3.0, 4.0, 4.0, 4.0)\n",
      "-5186369773851821684\n",
      "(5.0, 5.0, 1.0, 1.0, 5.0)\n",
      "7188167818581832279\n",
      "(4.0, 4.0, 1.0, 6.0, 2.0)\n",
      "-2876279330837645762\n",
      "(6.0, 6.0, 3.0, 3.0, 1.0)\n",
      "-5549349896442432323\n",
      "(1.0, 1.0, 4.0, 2.0, 5.0)\n",
      "8727413075815884501\n",
      "(3.0, 3.0, 5.0, 7.0, 6.0)\n",
      "-6509290990465855046\n",
      "(2.0, 4.0, 7.0, 3.0, 7.0)\n",
      "6937287777630625744\n",
      "(1.0, 1.0, 1.0, 2.0, 4.0)\n",
      "-5421266752020017951\n",
      "(3.0, 3.0, 2.0, 4.0, 1.0)\n",
      "2299775718567022248\n",
      "(7.0, 5.0, 3.0, 1.0, 5.0)\n",
      "1958459289187651019\n",
      "(6.0, 3.0, 4.0, 2.0, 7.0)\n",
      "-6624580685042100277\n",
      "(3.0, 2.0, 3.0, 4.0, 4.0)\n",
      "2714184780816481098\n",
      "(1.0, 4.0, 2.0, 3.0, 1.0)\n",
      "8521026909750998420\n",
      "(4.0, 1.0, 1.0, 1.0, 5.0)\n",
      "2615828169275698129\n",
      "(4.0, 3.0, 3.0, 4.0, 7.0)\n",
      "-2976643019373762080\n",
      "(1.0, 2.0, 4.0, 1.0, 4.0)\n",
      "-7408882273051786728\n",
      "(3.0, 1.0, 1.0, 3.0, 3.0)\n",
      "5484468455841355882\n",
      "(5.0, 7.0, 5.0, 5.0, 1.0)\n",
      "-7330077508101597928\n",
      "(6.0, 3.0, 1.0, 2.0, 6.0)\n",
      "4645700671776926483\n",
      "(1.0, 1.0, 3.0, 1.0, 1.0)\n",
      "3027994093183893294\n",
      "(3.0, 5.0, 2.0, 5.0, 3.0)\n",
      "-7337892274742340528\n",
      "(5.0, 6.0, 7.0, 6.0, 5.0)\n",
      "-3182980436076274714\n",
      "(3.0, 3.0, 7.0, 6.0, 4.0)\n",
      "4493039707683871993\n",
      "(2.0, 1.0, 4.0, 1.0, 1.0)\n",
      "-2905378342923790153\n",
      "(1.0, 2.0, 3.0, 3.0, 5.0)\n",
      "1604505913160721274\n",
      "(7.0, 4.0, 1.0, 5.0, 2.0)\n",
      "-6196245679375620429\n",
      "(7.0, 3.0, 1.0, 3.0, 1.0)\n",
      "-3096271077776350292\n",
      "(4.0, 2.0, 5.0, 2.0, 3.0)\n",
      "4276820716575543806\n",
      "(1.0, 4.0, 2.0, 4.0, 4.0)\n",
      "3648281588252767212\n",
      "(5.0, 1.0, 6.0, 1.0, 5.0)\n",
      "5290870465119954757\n",
      "(3.0, 2.0, 7.0, 6.0, 3.0)\n",
      "-6246674267228101022\n",
      "(1.0, 3.0, 1.0, 3.0, 5.0)\n",
      "5815812425369052356\n",
      "(5.0, 4.0, 2.0, 2.0, 4.0)\n",
      "-7258602124196074036\n",
      "(6.0, 5.0, 3.0, 7.0, 2.0)\n",
      "-3598911526647795709\n",
      "(1.0, 5.0, 6.0, 3.0, 7.0)\n",
      "-6409020527621297039\n",
      "(5.0, 1.0, 2.0, 5.0, 1.0)\n",
      "5720247349657271711\n",
      "(4.0, 3.0, 4.0, 4.0, 5.0)\n",
      "4714491011594936771\n",
      "(2.0, 7.0, 1.0, 2.0, 2.0)\n",
      "2602666969716845704\n",
      "(1.0, 7.0, 3.0, 5.0, 2.0)\n",
      "-1473191007735294089\n",
      "(2.0, 4.0, 1.0, 2.0, 1.0)\n",
      "-1083050323517257912\n",
      "(3.0, 3.0, 2.0, 6.0, 3.0)\n",
      "-1388735624981262248\n",
      "(4.0, 1.0, 4.0, 3.0, 7.0)\n",
      "-5718850601243316085\n",
      "(2.0, 4.0, 2.0, 6.0, 7.0)\n",
      "5536828757461059931\n",
      "(3.0, 2.0, 3.0, 4.0, 2.0)\n",
      "5497975436671547167\n",
      "(1.0, 1.0, 4.0, 1.0, 3.0)\n",
      "-8896839878282723481\n",
      "(4.0, 7.0, 5.0, 2.0, 4.0)\n",
      "-9819036803362928\n",
      "(3.0, 1.0, 4.0, 2.0, 1.0)\n",
      "-1481099218734153108\n",
      "(4.0, 5.0, 5.0, 1.0, 5.0)\n",
      "-5550086620668919418\n",
      "(1.0, 2.0, 2.0, 3.0, 2.0)\n",
      "7100332780042007280\n",
      "(5.0, 6.0, 6.0, 7.0, 6.0)\n",
      "7454786060936019256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 3683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = lsh(min_hash_signatures)\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3684,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidates_similarities(candidate_docs, min_hash_matrix):\n",
    "    similarity_dict = {}\n",
    "    #t = parameters_dictionary['t']\n",
    "    t = 0.5\n",
    "\n",
    "    for candidate_pair in candidate_docs:\n",
    "\n",
    "        doc1, doc2 = list(candidate_pair)\n",
    "\n",
    "        agreement = np.sum(\n",
    "            min_hash_matrix[:, doc1] == min_hash_matrix[:, doc2])\n",
    "\n",
    "        similarity = agreement / min_hash_matrix.shape[0]\n",
    "\n",
    "        if similarity > t:\n",
    "            similarity_dict[candidate_pair] = similarity\n",
    "\n",
    "    return similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 3685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = candidates_similarities(candidates, min_hash_signatures)\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3686,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hash_functions(num_perm, N):\n",
    "    hash_funcs = []\n",
    "    for i in range(1, num_perm + 1):\n",
    "        a = random.randint(1, N)\n",
    "        b = random.randint(0, N)\n",
    "        p = next_prime(N)\n",
    "        hash_func = (lambda x, a=a, b=b, p=p: ((a * x + b) %\n",
    "                     (p)) + 1, {'a': a, 'b': b, 'p': p})\n",
    "        hash_funcs.append(hash_func)\n",
    "    return hash_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<function __main__.generate_hash_functions.<locals>.<lambda>(x, a=4, b=1, p=7)>,\n",
       "  {'a': 4, 'b': 1, 'p': 7}),\n",
       " (<function __main__.generate_hash_functions.<locals>.<lambda>(x, a=6, b=1, p=7)>,\n",
       "  {'a': 6, 'b': 1, 'p': 7}),\n",
       " (<function __main__.generate_hash_functions.<locals>.<lambda>(x, a=4, b=0, p=7)>,\n",
       "  {'a': 4, 'b': 0, 'p': 7})]"
      ]
     },
     "execution_count": 3687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_funcs = generate_hash_functions(3, len(input_matrix))\n",
    "hash_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash function #0: a=4, b=3, p=7\n",
      "Hash function #1: a=1, b=5, p=7\n",
      "Hash function #2: a=2, b=2, p=7\n",
      "Hash function #3: a=6, b=0, p=7\n",
      "Hash function #4: a=6, b=5, p=7\n",
      "Hash function #5: a=3, b=1, p=7\n",
      "Hash function #6: a=4, b=1, p=7\n",
      "Hash function #7: a=5, b=2, p=7\n",
      "Hash function #8: a=3, b=5, p=7\n",
      "Hash function #9: a=3, b=0, p=7\n",
      "Hash function #10: a=6, b=6, p=7\n",
      "Hash function #11: a=4, b=2, p=7\n",
      "Hash function #12: a=2, b=4, p=7\n",
      "Hash function #13: a=4, b=6, p=7\n",
      "Hash function #14: a=6, b=5, p=7\n",
      "Hash function #15: a=5, b=2, p=7\n",
      "Hash function #16: a=2, b=1, p=7\n",
      "Hash function #17: a=6, b=3, p=7\n",
      "Hash function #18: a=2, b=2, p=7\n",
      "Hash function #19: a=1, b=6, p=7\n",
      "Hash function #20: a=5, b=0, p=7\n",
      "Hash function #21: a=6, b=3, p=7\n",
      "Hash function #22: a=1, b=3, p=7\n",
      "Hash function #23: a=5, b=3, p=7\n",
      "Hash function #24: a=6, b=6, p=7\n",
      "Hash function #25: a=6, b=4, p=7\n",
      "Hash function #26: a=6, b=0, p=7\n",
      "Hash function #27: a=1, b=3, p=7\n",
      "Hash function #28: a=6, b=0, p=7\n",
      "Hash function #29: a=6, b=1, p=7\n",
      "Hash function #30: a=6, b=5, p=7\n",
      "Hash function #31: a=4, b=4, p=7\n",
      "Hash function #32: a=3, b=6, p=7\n",
      "Hash function #33: a=5, b=6, p=7\n",
      "Hash function #34: a=1, b=2, p=7\n",
      "Hash function #35: a=4, b=6, p=7\n",
      "Hash function #36: a=2, b=5, p=7\n",
      "Hash function #37: a=4, b=2, p=7\n",
      "Hash function #38: a=4, b=2, p=7\n",
      "Hash function #39: a=6, b=0, p=7\n",
      "Hash function #40: a=2, b=3, p=7\n",
      "Hash function #41: a=2, b=3, p=7\n",
      "Hash function #42: a=6, b=0, p=7\n",
      "Hash function #43: a=5, b=5, p=7\n",
      "Hash function #44: a=6, b=1, p=7\n",
      "Hash function #45: a=4, b=1, p=7\n",
      "Hash function #46: a=5, b=3, p=7\n",
      "Hash function #47: a=1, b=6, p=7\n",
      "Hash function #48: a=4, b=2, p=7\n",
      "Hash function #49: a=4, b=6, p=7\n",
      "Hash function #50: a=4, b=5, p=7\n",
      "Hash function #51: a=4, b=2, p=7\n",
      "Hash function #52: a=6, b=3, p=7\n",
      "Hash function #53: a=2, b=1, p=7\n",
      "Hash function #54: a=4, b=6, p=7\n",
      "Hash function #55: a=5, b=3, p=7\n",
      "Hash function #56: a=6, b=2, p=7\n",
      "Hash function #57: a=3, b=2, p=7\n",
      "Hash function #58: a=5, b=3, p=7\n",
      "Hash function #59: a=5, b=6, p=7\n",
      "Hash function #60: a=2, b=5, p=7\n",
      "Hash function #61: a=1, b=2, p=7\n",
      "Hash function #62: a=2, b=0, p=7\n",
      "Hash function #63: a=6, b=1, p=7\n",
      "Hash function #64: a=2, b=5, p=7\n",
      "Hash function #65: a=6, b=2, p=7\n",
      "Hash function #66: a=5, b=2, p=7\n",
      "Hash function #67: a=5, b=6, p=7\n",
      "Hash function #68: a=2, b=5, p=7\n",
      "Hash function #69: a=4, b=3, p=7\n",
      "Hash function #70: a=4, b=6, p=7\n",
      "Hash function #71: a=4, b=2, p=7\n",
      "Hash function #72: a=4, b=0, p=7\n",
      "Hash function #73: a=4, b=2, p=7\n",
      "Hash function #74: a=6, b=0, p=7\n",
      "Hash function #75: a=1, b=2, p=7\n",
      "Hash function #76: a=1, b=1, p=7\n",
      "Hash function #77: a=1, b=6, p=7\n",
      "Hash function #78: a=5, b=5, p=7\n",
      "Hash function #79: a=2, b=2, p=7\n",
      "Hash function #80: a=5, b=0, p=7\n",
      "Hash function #81: a=3, b=4, p=7\n",
      "Hash function #82: a=3, b=5, p=7\n",
      "Hash function #83: a=2, b=2, p=7\n",
      "Hash function #84: a=3, b=6, p=7\n",
      "Hash function #85: a=1, b=0, p=7\n",
      "Hash function #86: a=5, b=6, p=7\n",
      "Hash function #87: a=5, b=2, p=7\n",
      "Hash function #88: a=4, b=4, p=7\n",
      "Hash function #89: a=4, b=1, p=7\n",
      "Hash function #90: a=3, b=1, p=7\n",
      "Hash function #91: a=1, b=3, p=7\n",
      "Hash function #92: a=1, b=1, p=7\n",
      "Hash function #93: a=1, b=5, p=7\n",
      "Hash function #94: a=6, b=6, p=7\n",
      "Hash function #95: a=3, b=2, p=7\n",
      "Hash function #96: a=4, b=0, p=7\n",
      "Hash function #97: a=3, b=3, p=7\n",
      "Hash function #98: a=4, b=1, p=7\n",
      "Hash function #99: a=4, b=0, p=7\n"
     ]
    }
   ],
   "source": [
    "for permutation, (hash_func, params) in enumerate(hash_fn):\n",
    "    print(\n",
    "        f\"Hash function #{permutation}: a={params['a']}, b={params['b']}, p={params['p']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 6., 3., 1., 6., 2., 2., 3., 6., 1.])"
      ]
     },
     "execution_count": 3689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_in = min_hash_signatures[0:10, 0]\n",
    "tuple_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4829124873993804287"
      ]
     },
     "execution_count": 3690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band_slice = tuple(tuple_in)\n",
    "\n",
    "\n",
    "band_hash = hash(band_slice)\n",
    "band_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
